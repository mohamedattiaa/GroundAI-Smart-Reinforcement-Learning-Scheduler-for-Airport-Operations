rag_system:
  # Embedding model
  embedding_model: "all-MiniLM-L6-v2"  # Fast, good quality
  # Alternative options:
  # - "all-mpnet-base-v2"  # Better quality, slower
  # - "paraphrase-MiniLM-L6-v2"  # Paraphrase-focused
  
  # Vector store
  vector_store:
    type: "chromadb"
    persist_directory: "data/processed/chroma_db"
    collection_name: "airport_scenarios"
    distance_metric: "cosine"
  
  # Retrieval parameters
  retrieval:
    default_k: 5  # Number of results to retrieve
    max_k: 20
    min_similarity: 0.5  # Minimum similarity score (0-1)
  
  # LLM configuration
  llm:
    provider: "ollama"  # Local LLM
    model_name: "mistral:7b-instruct"
    api_url: "http://localhost:11434/api/generate"
    
    generation_params:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 1000
      stop_sequences: ["\n\n\n"]
    
    # Fallback for when Ollama is not available
    fallback: "rule_based"
  
  # Prompt templates
  prompts:
    system_message: |
      You are an expert in airport ground handling operations and scheduling.
      You help optimize aircraft turnaround operations by analyzing historical 
      scenarios and providing data-driven recommendations.
    
    context_template: |
      Relevant historical scenarios:
      {contexts}
    
    question_template: |
      Question: {question}
      
      Provide a detailed, actionable answer based on the historical scenarios.
      Include specific recommendations and explain your reasoning.
  
  # Performance
  batch_size: 32
  cache_embeddings: true
  cache_directory: "data/processed/embeddings"